---
title: "R Markdown ~ Assignment"
author: "Khushi"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

```
```{r eval=TRUE, include=FALSE}
#Loading the Data
#rm(list=ls()) #Clean Memory
load("/Users/khushisampat/Desktop/Data Science/yelp_user_small.Rda")
load("/Users/khushisampat/Desktop/Data Science/yelp_review_small.Rda")
#Merging the two datasets
merged_data <- merge(user_data_small, review_data_small, by = "user_id")

library(jsonlite)
install.packages("tidyr")
library(tidyr)

#Setting Directory
 setwd("/Users/khushisampat/Desktop/Data Science")
#Loading Data
business_data <- stream_in(file("yelp_academic_dataset_business.json"))
#Merging the datset
Merged_data1 <- merge(merged_data, business_data, by = "business_id")
#The last colum is a df, hence unnesting the colums
Merged_data1 <- unnest(Merged_data1, cols = attributes)
Merged_data1 <- unnest(Merged_data1, cols=hours)
#Ommiting rows with missing values of stars.x
Merged_data1 <- Merged_data1[!is.na(Merged_data1$stars.x), ]

#Checking distribution and Balance of Stars.x (number of stars given by user i to business j)
install.packages("ggplot2")
library(ggplot2)
# Install the dplyr package
install.packages("dplyr")

# Load the dplyr package
library(dplyr)

# Useing ggplot2 to plot
ggplot(Merged_data1, aes(x = stars.x)) +
  geom_bar(fill = "blue") +
  labs(title = "Distribution of Stars", x = "Stars", y = "Frequency") +
  theme_minimal()

# Calculating the frequency and percentage of each category
Merged_data1_summary <- Merged_data1 %>%
  group_by(stars.x) %>%
  summarise(count = n()) %>%
  mutate(percentage = (count / sum(count)) * 100)

# Arranging categories if they have a specific order
Merged_data1_summary$stars.x <- factor(Merged_data1_summary$stars.x, levels = c("1", "2", "3", "4", "5")) 

#Creating Bar Graph
ggplot(Merged_data1_summary, aes(x = stars.x, y = percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  ylab("Percentage") +
  xlab("Stars") +
  ggtitle("Distribution of Categories") +
  theme_minimal()

#We can see that the dataset is imbalanced

#Creating a Balanced Data Set 
install.packages("dplyr")
library(dplyr)

subdata <- Merged_data1[, 3:40] #After EDA getting rid of colums that do not significantly influence stars.x ~ reducing noise
subdata <- subdata %>% select(-is_open, -postal_code, -state, -city, -yelping_since, -elite, -friends, -fans, -compliment_cool, -compliment_cute, -compliment_hot, -compliment_more, -compliment_list, compliment_note, -compliment_plain, -compliment_profile, -compliment_writer, -compliment_photos, -review_id, -useful.y, -funny.y, -cool.y, -text, -date, -name.x, -name.y, -address)

classes <- sort(unique(subdata$stars.x))
balanced_data <- data.frame()

for(class in classes) {
  class_data <- subdata[subdata$stars.x == class, ]
  sampled_data <- class_data %>% 
    slice_sample(n = max(table(subdata$stars.x)), replace = TRUE)  # Oversampling
  balanced_data <- rbind(balanced_data, sampled_data)
}

# Shuffle the rows to mix the classes
set.seed(1)
balanced_data <- balanced_data[sample(nrow(balanced_data)), ]


# ~ Please upload data and run code till here before testing every model


#EDA
library(ggplot2)
ggplot(Merged_data1)+geom_point(mapping=aes(x=review_count.x, y=stars.x)) + xlim(0,5000)

max(user_data_small$useful)
table<- table(user_data_small$useful)
print(table) 
ggplot(Merged_data1)+geom_point(mapping=aes(x=useful.x, y=stars.x)) + xlim(0,1000)

ggplot(Merged_data1)+geom_point(mapping=aes(x=funny.x, y=stars.x)) + xlim(0,5000)

ggplot(Merged_data1)+geom_point(mapping=aes(x=funny.x, y=stars.x)) + xlim(0,1000)

max(user_data_small$cool)
ggplot(Merged_data1)+geom_point(mapping=aes(x=cool.x, y=stars.x)) + xlim(0,1000)

ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_more, y=stars.x)) + xlim(0, 500)

ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_profile, y=stars.x)) + xlim(0, 400)

ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_cute, y=stars.x)) + xlim(0, 400)

ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_list, y=stars.x)) + xlim(0, 400)
ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_list, y=stars.x)) + xlim(0, 200)

ggplot(Merged_data1)+geom_point(mapping=aes(x=compliment_note, y=stars.x)) + xlim(0, 3000) 

ggplot(Merged_data1)+geom_point(mapping=aes(x=useful.y, y=stars.x)) + xlim(0, 1000)

ggplot(Merged_data1)+geom_point(mapping=aes(x=funny.y, y=stars.x)) + xlim(0, 1000)

ggplot(Merged_data1)+geom_point(mapping=aes(x=review_count.y, y=stars.x)) + xlim(0, 5000)

#Spacial EDA - collecting data to conduct KNN

library(dplyr)

average_ratings_by_city <- Merged_data1 %>%
       group_by(city, state) %>%
      summarize(avg_rating = mean(stars.x, na.rm = TRUE))

average_ratings_by_city <- Merged_data1 %>%
       group_by(city) %>%
       summarize(avg_rating = mean(stars.x, na.rm = TRUE))
   
   # Viewing the result
print(average_ratings_by_city)

city_business_data <- Merged_data1 %>%
       filter(city == "Philadelphia") %>%
       group_by(business_id) %>%
       summarize(latitude = first(latitude),  # Useing the actual latitude
                                 longitude = first(longitude),  # Useing the actual longitude
                                 avg_stars = mean(stars.x, na.rm = TRUE))


ggplot(city_business_data, aes(x = longitude, y = latitude, color = as.factor(round(avg_stars)))) +
       geom_point() +
      scale_color_manual(values = c("1" = "red", "2" = "blue", "3" = "yellow", "4" = "green", "5" = "purple")) +
       labs(title = paste("Average Star Ratings per Business in", "Philidelphia"), 
                       x = "Longitude", y = "Latitude", color = "Average Star Rating") +
       theme_minimal()


city_business_data <- Merged_data1 %>%
      filter(city == "Saint Louis") %>%
       group_by(business_id) %>%
       summarize(latitude = first(latitude),  # Using the actual latitude
                                 longitude = first(longitude),  # Using the actual longitude
                                 avg_stars = mean(stars.x, na.rm = TRUE))

ggplot(city_business_data, aes(x = longitude, y = latitude, color = as.factor(round(avg_stars)))) +
       geom_point() +
       scale_color_manual(values = c("1" = "red", "2" = "blue", "3" = "yellow", "4" = "green", "5" = "purple")) +
       labs(title = paste("Average Star Ratings per Business in", "Saint Louis"), 
                       x = "Longitude", y = "Latitude", color = "Average Star Rating") +
       theme_minimal()

city_business_data <- Merged_data1 %>%
       filter(city == "Tampa") %>%
       group_by(business_id) %>%
       summarize(latitude = first(latitude),  # Using the actual latitude
                                 longitude = first(longitude),  # Using the actual longitude
                                 avg_stars = mean(stars.x, na.rm = TRUE))

  
   
ggplot(city_business_data, aes(x = longitude, y = latitude, color = as.factor(round(avg_stars)))) +
       geom_point() +
       scale_color_manual(values = c("1" = "red", "2" = "blue", "3" = "yellow", "4" = "green", "5" = "purple")) +
       labs(title = paste("Average Star Ratings per Business in", "Tampa"), 
                       x = "Longitude", y = "Latitude", color = "Average Star Rating") +
       theme_minimal()



 #Experimenting with different Models and Methods ~ Please Upload Data and run the first few lines before running every model
 
#Simple always 5 classifier
 # Creating a vector of predictions where every prediction is 5
 predictions <- rep(5, nrow(subdata))
 # Calculate accuracy
 actual <- subdata$stars.x  # Replace 'stars.x' with the actual column name
 accuracy <- sum(predictions == actual) / length(actual)
 print(paste("Accuracy:", accuracy))
 #0.461 accuracy


#KNN
subdataKnn <- subdata[, c("latitude", "longitude", "stars.x")]
# Install the class package
install.packages("class")

# Load the class package
library(class)


x <- subdataKnn[, -which(names(subdataKnn) == "stars.x")]  # Predictor variables
y <- subdataKnn$stars.x  # Target variable

# Splitting the data into training and test sets
set.seed(1)  # Setting seed for reproducibility
index <- sample(1:nrow(x), round(0.75*nrow(x)))
train_x <- x[index, ]
train_y <- y[index]
test_x <- x[-index, ]
test_y <- y[-index]

# Scaling the data
train_x_scaled <- scale(train_x)
test_x_scaled <- scale(test_x, center = attr(train_x_scaled, "scaled:center"), scale = attr(train_x_scaled, "scaled:scale"))

library(caret)
set.seed(1)
tune_grid <- expand.grid(k = 1:20)
control <- trainControl(method = "cv", number = 10)
knn_tune <- train(x = train_x_scaled, y = train_y, method = "knn", trControl = control, tuneGrid = tune_grid)
# Plotting tuning results
plot(knn_tune)
# Best model's k value
optimal_k <- knn_tune$bestTune$k

# Fitting KNN model
set.seed(1)
knn_pred <- knn(train = train_x_scaled, test = test_x_scaled, cl = train_y, k = 20)

# Confusion Matrix
table(Predicted = knn_pred, Actual = test_y)

# Accuracy
mean(knn_pred == test_y)


average_stars_by_state <- subdataKnn %>%
  group_by(state) %>%
  summarize(average_stars = mean(stars.x, na.rm = TRUE))
ggplot(average_stars_by_state, aes(x = state, y = average_stars)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme_minimal() +
  labs(x = "State", y = "Average Star Rating", title = "Average Star Rating by State") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  

# Or create a simple plot
ggplot(average_ratings, aes(x = region, y = average_rating)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Average Ratings by Region")

#Neural Networks


library(keras)
install.packages("dplyr")
install.packages("caret")

library(dplyr)
library(caret)
install.packages("nnet")
library(nnet)


#Imputing missing values with the median for numeric columns
subdata <- subdata %>%
  mutate_if(is.numeric, ~ifelse(is.na(.), median(., na.rm = TRUE), .))


subdata$stars.x <- as.factor(subdata$stars.x)

numeric_columns <- sapply(subdata, is.numeric)
subdata[numeric_columns] <- scale(subdata[numeric_columns])

set.seed(1) # for reproducibility
train_index <- sample(1:nrow(balanced_data), 0.8 * nrow(balanced_data)) 
train_data <- subdata[train_index, ]
test_data <- subdata[-train_index, ]

model <- nnet(stars.x ~ ., data = train_data, size = 10, decay = 0.1, maxit = 200)

predictions <- predict(model, test_data, type = "class")
confusionMatrix <- table(predictions, test_data$stars.x)
print(confusionMatrix)

accuracy <- sum(predictions == test_data$stars.x) / nrow(test_data)
print(paste("Accuracy:", accuracy))
#.57 with subdata 

#RandomForest

install.packages("randomForest")
library(randomForest)

balanced_data <- lapply(balanced_data, function(x) if(is.character(x)) factor(x) else x) #changing variable storage type to factor
balanced_data <- na.omit(balanced_data) #omitting missing values
 # Convert the list back to a dataframe
balanced_data <- as.data.frame(balanced_data)

set.seed(1)  # Setting a seed for reproducibility
splitIndex <- createDataPartition(balanced_data$stars.x, p = 0.8, list = FALSE)
train_data <- balanced_data[splitIndex, ]
test_data <- balanced_data[-splitIndex, ]
train_data$stars.x <- as.factor(train_data$stars.x)

train_data <- lapply(train_data, function(x) ifelse(is.na(x), "false", x))
test_data <- lapply(test_data, function(x) ifelse(is.na(x), "false", x))

# Converting the lists back to dataframes
train_data <- as.data.frame(train_data)
test_data <- as.data.frame(test_data)

train_data$stars.x <- as.factor(train_data$stars.x)
test_data$stars.x <- as.factor(test_data$stars.x)

#Applying k-fold cross validation
control <- trainControl(method = "cv", number = 10)
set.seed(1)  # for reproducibility
#training
model_cv <- train(stars.x ~ ., data = train_data, method = "rf", trControl = control, ntree = 100)
#testing
predictions <- predict(model_cv, test_data)
#Accuracy
accuracy <- mean(predictions == test_data$stars.x)
print(paste("Accuracy:", accuracy))

rf_model <- randomForest(stars.x ~ ., data = train_data, ntree = 100, na.action = na.pass) 

install.packages("randomForest")
library(randomForest)

# Calculating feature importance
feature_importance <- importance(rf_model)

# Viewing the feature importance
print(feature_importance)

#visualizing the feature importance
install.packages("ggplot2")
library(ggplot2)

# Converting to a data frame for plotting
feature_importance_df <- as.data.frame(feature_importance)
feature_importance_df$Feature <- row.names(feature_importance_df)

# Plotting feature importance
ggplot(feature_importance_df, aes(x = reorder(Feature, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("Feature") +
  ylab("Importance") +
  ggtitle("Feature Importance in Random Forest Model")

#.4639 with RF and 0.5835 with NN 0.57 with subdata #0.933 for balanced_data where NN and RF were differnt combinations of variables picked for smaller subsets
install.packages("caret")
library(caret)

# Confusion matrix and associated statistics
confusionMatrix(predictions, as.factor(test_data$stars.x))

```

## Analysis of Method - Report

The DS Methodology that I decided to follow was the CRISP-DM Method because it lent itself perfectly to my approach.
I applied it by structuring my approach based on the iterative life-cycle process.

1\.
Understand Business Needs: Use data to predict review in terms of number of stars that user I gives business j

2\.
Data understanding: EDA, understanding how data can be used to answer the question.

3\.
Data Preparation: Different Models require the data to be preprocessed differently.

4\.
Modelling: Create the model

5\.
Evaluation: Run Model on test data and see how it fares

6\.
Deployment: This analysis report falls under this category.

The challenge I found most difficult was picking the combination of variables to create smaller sub datasets.
I did this my visualizing the correlation and manually putting them into groups.
Alternatively, a feature importance method could have been used.

**Introduction**

The aim of the model is to predict the number of stars a business will receive in a review.
Since it can only receive a discrete number between 1-5 inclusive, I've treated this as a classification problem rather than a regression problem and hence changed variable storage type to a factor variable.

We have been given 5 datasets out of which I chose to work with user_small, review_small and business.
json.
I used user_id and business id to merge them all to create a single dataset called Merged_data1.

**Data Preprocessing and EDA**

Merged_data1 has 87 columns, 279878 observation and a mix of different types of variables.
Since the brief is to predict stars.x, it is essential to first understand its distribution.

```{r}
ggplot(Merged_data1_summary, aes(x = stars.x, y = percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  ylab("Percentage") +
  xlab("Stars") +
  ggtitle("Distribution of Categories") +
  theme_minimal()
```

Plotting its distribution, we observe an imbalance in classes which can prove to be problematic.
To account for this, I oversampled underrepresented classes to the same level as the largest class.

To understand the relationship between different variables and stars.x I used the ggplot2 package to visualize any patterns.

```{r}
ggplot(Merged_data1)+geom_point(mapping=aes(x=funny.x, y=stars.x)) + xlim(0,5000)
```

We observe here as funny.x increases, it is more probable that the business has a higher rating.
Variables which didn't showcase a strong correlation I discarded from the data hence creating smaller dataset "subdata" with lower dimensionality and noise.

To investigate the impact of location on rating I use the latitude and longitude variables.
My hypothesis was that if the business was in a better neighborhood, it would have a higher rating and hence clustering of classes would be observed.

```{r}
ggplot(city_business_data, aes(x = longitude, y = latitude, color = as.factor(round(avg_stars)))) +
       geom_point() +
       scale_color_manual(values = c("1" = "red", "2" = "blue", "3" = "yellow", "4" = "green", "5" = "purple")) +
       labs(title = paste("Average Star Ratings per Business in", "Tampa"), 
                       x = "Longitude", y = "Latitude", color = "Average Star Rating") +
       theme_minimal()
```

Tampa didn't have any clear indications of clustering of rating of the same class whereas Philadelphia did as seen below which could be because Philadelphia houses more tourist who are more likely to leave reviews.

```{r}
ggplot(city_business_data, aes(x = longitude, y = latitude, color = as.factor(round(avg_stars)))) +
       geom_point() +
      scale_color_manual(values = c("1" = "red", "2" = "blue", "3" = "yellow", "4" = "green", "5" = "purple")) +
       labs(title = paste("Average Star Ratings per Business in", "Philidelphia"), 
                       x = "Longitude", y = "Latitude", color = "Average Star Rating") +
       theme_minimal()
```

As we can see, there seems to be a concentration of 1 star rating in the Centre but higher ratings in the suburbs which are the nicer areas.

```{r}
ggplot(average_stars_by_state, aes(x = state, y = average_stars)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme_minimal() +
  labs(x = "State", y = "Average Star Rating", title = "Average Star Rating by State") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

Here we can see the difference in average ratings by state.

**MODELS**

The first model I decided to run was a simple classifier that always predicts 5 as that's the highest class in the data.
The accuracy of this model was 46%.
Which I will treat as baseline

The next model I decided to run was a KNN model.
K-Nearest Neighbors (KNN) is a simple, non-parametric classification algorithm that assigns a class to a new data point based on the majority class among its k-nearest neighbors in the training set.
It calculates distances between data points, considering the closest `k` neighbors to determine the class.
My dataset included only stars.x, latitude and longitude and the model had an accuracy of 45%.
I believe it didn't fare too well because as seen in the Tampa and Philadelphia example there weren't prominent patterns to learn from.

Another model known to do well as a classifier is a neural network model.
Neural networks involve layers of interconnected nodes (neurons) that process input data through weights and activation functions.
They learn complex patterns by adjusting these weights during training, through backpropagation.
The output layer classifies input by assigning probabilities to each class, based on learned patterns.
This model yields an accuracy of 57%.
While this is better than the KNN model, a neural network setup should be significantly more powerful.
I believe it didn't perform well because it is prone to overfitting as it hones an exceptional learning rate and may have mistaken noise for complex patterns.

**Random Forest Model Analysis -- Main Model**

Random Forest is a robust ensemble learning technique ideal for classifying complex datasets with numerous predictors like ours.
By constructing multiple decision trees, each on a distinct bootstrap sample from the balanced dataset `balanced_data`, it captures a diverse range of data aspects.
Each tree in the ensemble considers a random subset of features for splitting nodes, preventing any single predictor from dominating the decision process.
This strategy enhances the model's robustness and prevents overfitting, which can be a significant risk.

The method does not rely on a singular loss function during training.
Instead, it uses measures like Gini impurity and entropy to assess the quality of splits within individual trees---where $Gini = 1 - \sum (p_i)^2$ and $Entropy = - \sum p_i \log_2(p_i)$, with $p_i$ representing the proportion of samples within the $i^{th}$ class.
These criteria allow the model to evaluate and minimize misclassification risk and data disorder, respectively.
Gini impurity quantifies the purity of a node, indicating the likelihood of a new sample being incorrectly classified if randomly assigned according to the distribution of samples in the node.
Entropy is used to measure the level of disorder or uncertainty in the data, with higher entropy reflecting more heterogeneity in the class distribution within a node.

Feature importance emerges naturally from the Random Forest algorithm, with more predictive features resulting in greater impurity reduction and, consequently, a higher importance score.
This is quantified post-training through metrics such as Mean Decrease in Impurity and Mean Decrease in Accuracy.

The method's structure inherently immune against missing data and outliers because it can address gaps in data through surrogate splits which is utilizing correlated features when primary splits fails, or by imputing missing values.
Since Random Forest is an ensemble of decision trees, and decision trees are non-parametric, they don't assume a particular distribution for the data.
Therefore, they are less affected by outliers than parametric methods that make specific assumptions about distribution, like linear regression.
To enhance the model's performance and robustness, k-fold cross-validation was employed.

The model achieved an accuracy of 94% in the test data and had a sensitivity of 0.97, 0.99, 0.98, 0.90, and 0.84 for each class 1-5 respectively.

```{r}
ggplot(feature_importance_df, aes(x = reorder(Feature, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  xlab("Feature") +
  ylab("Importance") +
  ggtitle("Feature Importance in Random Forest Model")

```

**Limitations**

While Random Forest is a robust and powerful model, it's important to note its limitations, such as the lack of transparency in how individual trees make decisions (the "black box" nature) and the computational complexity with very large datasets.

**Conclusion**

Given more time and computational resources such as GPU and CPU, there are many enhancements I would have liked to have made to the process to utilize the full dataset.
Sentiment analysis could have been conducted on the text of the reviews, feature selection could have been done on the entirety of Merged_data1 and through clustering selection, one impactful variable from each cluster could be used to create multiple sub datasets to test which ones work the best with the different models.
Additionally, the dataframe attributes could have been better utilised to compare and predict stars based on the similarity of the businesses as well through clustering.
Lastly, an intricate neural network could have been created, and an ensemble of all of these models to create a supremely accurate predictor.

**References**

1.  Grolemund, G. & Wickham, H. 2016. R for Data Science: Import, Tidy, Transform Visualise, and Model Data.
2.  Hastie, T.; Tibshirani, R.; Friedman, J. H.; & Friedman, J. H. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Vol. 2). New York: Springer
3.  James, G.; Witten, D.; Hastie, T.; & Tibshirani, R. 2021 (2nd Ed.). An Introduction to Statistical Learning with Applications in R. Springer.
